{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOakYOl77pe6lC8AWrdKdc2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/krisnasetyadi/texting/blob/master/BoW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QOHgALwSO0RG"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "paragraph = \"\"\"An Iranian Instagram star famous for her radical appearance and cosmetic surgery has been arrested for blashphemy by the Tehran Prosecutor's Office, according to the country's semi-official Tasnim News agency.\n",
        "Tasnim News said the influencer, who goes by Sahar Tabar on Instagram but was identified as Fatemeh Kh by Iranian media, using the first character of her surname in Farsi, is accused of promoting violence,illicit education,blasphemy, insulting the Islamic veil,spreading hate.\n",
        "That said, this is the probably the last time that we're going to do it this way. While it's nice to load and play premade datasets, it's very rare that we get to do that in the real world, so it essential that we learn how to start from a more raw dataset\"\"\""
      ],
      "metadata": {
        "id": "XTHokyV2O8N6"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenization , split \n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47Oy0-XvRcK3",
        "outputId": "751da854-e385-47c1-a2ec-f48c03320add"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = nltk.sent_tokenize(paragraph)"
      ],
      "metadata": {
        "id": "k3yGi6K8Rj29"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocessing buang karakter yg tidak perlu\n",
        "# buat iterasi\n",
        "for i in range(len(dataset)):\n",
        "  dataset[i]=dataset[i].lower()\n",
        "  # menghapus non word dg spasi\n",
        "  dataset[i]=re.sub(r'\\W',' ',dataset[i])\n",
        "  # mengganti spasi jamak jadi tunggal\n",
        "  dataset[i]=re.sub(r'\\s',' ',dataset[i])"
      ],
      "metadata": {
        "id": "eYaf_9ouRnrv"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# buat histogram, untuk liat kemunculan\n",
        "word2count = {}\n",
        "for klmt in dataset:\n",
        "  kata=nltk.word_tokenize(klmt)\n",
        "  for kt in kata:\n",
        "    if kt not in word2count.keys():\n",
        "      word2count[kt] = 1\n",
        "    else:\n",
        "        word2count[kt] = 2"
      ],
      "metadata": {
        "id": "qjkt42JKSFJv"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ambil 10 kata yg sering muncul\n",
        "import heapq\n",
        "# heapq = menghitung freq\n",
        "freq_words = heapq.nlargest(10,word2count,key=word2count.get)"
      ],
      "metadata": {
        "id": "uYp8ZuQbSlqw"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "freq_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FfvWKZHCS-Ca",
        "outputId": "03d211dc-36e8-418a-e864-5175f0b0feef"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['iranian', 'instagram', 'for', 'her', 'and', 'by', 'the', 's', 'to', 'tasnim']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# buat representasi klmt dalam vektor\n",
        "x= []\n",
        "for data in dataset:\n",
        "  vector = []\n",
        "  for word in freq_words:\n",
        "    if word in nltk.word_tokenize(data):\n",
        "      vector.append(1)\n",
        "    else:\n",
        "      vector.append(0)\n",
        "  x.append(vector)"
      ],
      "metadata": {
        "id": "96UJUtsITCib"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# buat array 2 dimensi\n",
        "import numpy as np\n",
        "x = np.asarray(x)"
      ],
      "metadata": {
        "id": "6xFM2L3-Tg13"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x\n",
        "# representasi Bag of Word model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4zyssrVjTrAx",
        "outputId": "fa13c840-5c7e-41f2-b658-0ff7515c09b0"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "       [1, 1, 0, 1, 0, 1, 1, 0, 0, 1],\n",
              "       [0, 0, 0, 0, 0, 0, 1, 0, 1, 0],\n",
              "       [0, 0, 0, 0, 1, 0, 1, 1, 1, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    }
  ]
}